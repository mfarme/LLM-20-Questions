{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61247,"databundleVersionId":8550470,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install flash-attn","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:14:29.749187Z","iopub.execute_input":"2024-07-08T11:14:29.749526Z","iopub.status.idle":"2024-07-08T11:14:58.795135Z","shell.execute_reply.started":"2024-07-08T11:14:29.749496Z","shell.execute_reply":"2024-07-08T11:14:58.794132Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting flash-attn\n  Downloading flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.1.2)\nCollecting einops (from flash-attn)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (2024.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl size=120576656 sha256=0f3dddbf9bc350ea6b0306ec5ca5fee71b57fe1f06e6b72672690793d9dad2ce\n  Stored in directory: /root/.cache/pip/wheels/cc/ad/f6/7ccf0238790d6346e9fe622923a76ec218e890d356b9a2754a\nSuccessfully built flash-attn\nInstalling collected packages: einops, flash-attn\nSuccessfully installed einops-0.8.0 flash-attn-2.5.9.post1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.system(\"pip install -t /tmp/submission/lib flash_attn\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:14:58.797414Z","iopub.execute_input":"2024-07-08T11:14:58.797796Z","iopub.status.idle":"2024-07-08T11:17:13.525093Z","shell.execute_reply.started":"2024-07-08T11:14:58.797758Z","shell.execute_reply":"2024-07-08T11:17:13.524190Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting flash_attn\n  Using cached flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl\nCollecting torch (from flash_attn)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting einops (from flash_attn)\n  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting filelock (from torch->flash_attn)\n  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\nCollecting typing-extensions>=4.8.0 (from torch->flash_attn)\n  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\nCollecting sympy (from torch->flash_attn)\n  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\nCollecting networkx (from torch->flash_attn)\n  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\nCollecting jinja2 (from torch->flash_attn)\n  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\nCollecting fsspec (from torch->flash_attn)\n  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->flash_attn)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->flash_attn)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->flash_attn)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->flash_attn)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->flash_attn)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->flash_attn)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch->flash_attn)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->flash_attn)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->flash_attn)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch->flash_attn)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch->flash_attn)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch->flash_attn)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->flash_attn)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch->flash_attn)\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting mpmath<1.4.0,>=1.1.0 (from sympy->torch->flash_attn)\n  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nUsing cached einops-0.8.0-py3-none-any.whl (43 kB)\nDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m976.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\nDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, einops, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, flash_attn\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndatasets 2.19.2 requires fsspec[http]<=2024.3.1,>=2023.1.0, but you have fsspec 2024.6.1 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.6.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ns3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.6.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stdout","text":"Successfully installed MarkupSafe-2.1.5 einops-0.8.0 filelock-3.15.4 flash_attn-2.5.9.post1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sympy-1.12.1 torch-2.3.1 triton-2.3.1 typing-extensions-4.12.2\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nfrom pathlib import Path\nimport shutil\n\nmodel_path = Path(\"/tmp/submission/\")\nif model_path.exists():\n    shutil.rmtree(model_path)\nmodel_path.mkdir(parents=True)\n\nsnapshot_download(\n    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n    local_dir=model_path\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:27:28.445732Z","iopub.execute_input":"2024-07-08T11:27:28.446519Z","iopub.status.idle":"2024-07-08T11:27:50.869886Z","shell.execute_reply.started":"2024-07-08T11:27:28.446484Z","shell.execute_reply":"2024-07-08T11:27:50.868661Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 19 files:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204a480060ce4dc785e9c51189c25983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8fe3e3ae21d4fdeab668cb249d0151f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE:   0%|          | 0.00/1.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26033f59820d487884a5db8f9c9423b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"NOTICE.md:   0%|          | 0.00/1.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9c5d9fe3c1492a9b5fc98984c9433d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"SECURITY.md:   0%|          | 0.00/2.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac85212b88624b3ea36e89203133fa0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5405cbf076b94e3c8f432321dd38b692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"CODE_OF_CONDUCT.md:   0%|          | 0.00/453 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161f660c06834b84a79d3bfd85faaac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/21.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73473ee1f3c34af785d37bfafb1058c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b2a22662e0b4ac3b36e8edfc53d0caa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4482d4b3b947bb9729d99a6ec3e8ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03e24b8dcfe4ceaa56ad34dfeef9768"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sample_finetune.py:   0%|          | 0.00/6.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c168cd83afed46479fe000717efbcc4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd8f9eeada24a4eb23c0a35866d6a06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0caa57178744f5da32bca13b5a9cebb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f448813118840f6af410c78307fd133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a1836efc2c2487cba91d006b3565f83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8fbc6888d9640bd9e9e2c19586b11c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"941e8aac5f2847899c39684e78e9b1e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e16d2c67d0478aa13f5b551ac36bdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826ff7845c2548818eea8b70c063adb3"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'/tmp/submission'"},"metadata":{}}]},{"cell_type":"code","source":"#%%writefile main.py\n\n# ====================ENV PATH========================\nimport os\n\nKAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\nif not os.path.exists(KAGGLE_AGENT_PATH):\n    KAGGLE_AGENT_PATH = \"/tmp/submission/\"\n\n# ====================IMPORTS========================\n\nimport sys\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(KAGGLE_AGENT_PATH, torch_dtype=\"auto\", device_map=\"cuda\", attn_implementation=\"eager\")\ntokenizer = AutoTokenizer.from_pretrained(KAGGLE_AGENT_PATH)\n\nimport itertools\nimport re\nimport torch\nimport typing as t\nfrom pathlib import Path\nfrom pydantic import BaseModel, Field\n\n# ====================CONSTANTS========================\n\nstr_strip = t.Annotated[str, Field(strip_whitespace=True)]\nmodel_initialized = False\ndevice = \"cuda\"\nDEBUG = None\n\n# =========================SYSTEM MESSAGE=========================\n\nsystem_message = f\"\"\"\nYou are playing the 20 questions game. The objective is to guess the secret keyword in as few guesses as possible. \nIn this game there are thousands of possible keywords within the categories of places and things. People are not included in this game.\nThe secret keyword is randomly selected. It is very specific. It could be a country, city, food, animal, tool, appliance, furniture, etc. But not a person. \n\"\"\"\n\n# ====================INITIALIZE MODEL =========================\n\ndef initialize_model(model, tokenizer, device=device):\n    global model_initialized\n    if not model_initialized: \n        device = \"cuda\"\n        model = model.to(device)\n        tokenizer = tokenizer\n        model_initialized = True  \n        \n# =========================DATA MODEL=========================\n\nclass Observation(BaseModel):\n    step: int\n    role: t.Literal[\"guesser\", \"answerer\"]\n    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]\n    keyword: str\n    category: str\n    questions: list[str]\n    answers: list[str]\n    guesses: list[str]\n    \n    @property\n    def empty(self) -> bool:\n        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])\n    \n    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")\n\n    def get_history_as_xml(self, *, skip_guesses: bool = False, skip_answer: bool = False, skip_question: bool = False) -> str:\n        if not self.empty:\n            history = \"\\n\".join(\n            f\"\"\"\\\n            {'Question: ' + question if not skip_question else ''}\n            {'Answer: ' + answer if not skip_answer else ''}\n            {'Guess: ' + guess if not skip_guesses else ''}\n            \"\"\"\n            for i, (question, answer, guess) in enumerate(self.get_history())\n            )\n            return history\n        return \"none yet.\"\n\n\n# =========================ASK AGENT=========================\n\ndef ask(observation: Observation) -> str:\n    if observation.step == 0:\n        return \"Is the secret keyword a place?\"\n    elif observation.step == 1:\n        if len(observation.answers) > 0 and observation.answers[0] == \"yes\":\n            return \"Is it in the western hemisphere?\"\n        else:\n            return \"Is it a living thing?\"\n    elif observation.step == 2:\n        if len(observation.answers) > 0 and observation.answers[0] == \"yes\":\n            return \"Is the place natural and not man-made?\"\n        else:\n            return \"Is it related to food or drinks?\"\n\n    branch = determine_branch(observation)\n    \n\n    try:\n        hx_text = assess_history(branch, observation)\n        if DEBUG:\n            print(\"DEBUG_____ASSESS HISTROY PROMPT (QUESTIONER)\", hx_text)\n        hx_text = generate_text_long(hx_text)\n        chain_of_thought_text = thinking(hx_text, observation)\n        if DEBUG:\n            print(\"DEBUG_____THINKING PROMPT (QUESTIONER)\", chain_of_thought_text)\n        chain_of_thought_text = generate_text_long(chain_of_thought_text)\n        response = chain_of_thought_text\n        if DEBUG:\n            print(\"DEBUG_____QUESTION PASRING PROMPT (QUESTIONER)\", response)\n        q_parsed = parse_question(response)\n        q_parsed = parse_response_generation(q_parsed)\n        return q_parsed\n    except Exception as e:\n        print(f\"Error while asking question: {e}\")\n        return 'Is it a person?'\n\ndef determine_branch(observation: Observation) -> str:\n    \"\"\"\n    Determine the branch based on the Q&A history.\n    \"\"\"\n    place_questions = {\n        \"Is it in the western hemisphere?\": \"Place in Western Hemisphere\",\n        \"Is the place natural and not man-made?\": \"Natural place, not man-made\",\n    }\n    \n    thing_questions = {\n        \"Is it a living thing?\": \"a living thing\",\n        \"Is it related to food?\": \"related to food or drink\",\n    }\n\n    for question, answer in zip(observation.questions, observation.answers):\n        if observation.questions[0] == \"Is the secret keyword a place?\" and observation.answers[0] == \"yes\":\n            if question in place_questions and answer == \"yes\":\n                return place_questions[question]\n        elif observation.questions[0] == \"Is the secret keyword a place?\" and observation.answers[0] == \"no\":\n            if question in thing_questions and answer == \"yes\":\n                return thing_questions[question]\n    \n    if observation.questions[0] == \"Is the secret keyword a place?\" and observation.answers[0] == \"yes\":\n        return \"place\"\n    else:\n        return \"thing\"\n    \ndef assess_history(branch, observation):\n    prompt = f\"\"\"\n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n    {observation.get_history_as_xml(skip_guesses=False)}\n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the incorrect guesses, if any. We know that these are incorrect since the game is still in progress. \n    - We know the the keyword is a {branch} based on the questions asked and the answers provided. What specific {branch} is the keyword?\n    \"\"\"\n    return prompt\n\ndef thinking(hx_text, observation):\n    prompt = f\"\"\"\n    You are thinking about what question to ask next. You have the following information to consider:\n    \n    {hx_text}\n\n    Based on the information above, what is the next question you would like to ask to bisect the search space and narrow down the possibilities?\n    If categories are still unclear, it may be best to ask a yes/no question that narrows the known category down further. You are not allowed to ask questions that are not yes/no.\n    Your response should start with your reasoning, then you say therefore my next quesiton is:\n    \"\"\"\n    return prompt\n\ndef parse_question(response:str) -> str:\n    prompt = f\"\"\"\n    Your role is to take text below and parse a single valid question for the game of 20 questions. You do not provide extra details. Just the question based on the text provided.\n    It should be formatted as a question and end with a question mark. Limit the question to 50 characters. If a list is provided, use the first item. \n    Here is the text:\n    \n    \"{response}\"\n\n    Reply with the single question.\n    \"\"\"\n    return prompt\n    \n#=========================ANSWER AGENT=========================\n\ndef answer(observation: \"Observation\") -> t.Literal[\"yes\", \"no\"]:\n    if not observation.keyword:\n        print(\"Keyword wasn't provided to answerer\", file=sys.stderr)\n        return \"yes\"  # Default to \"yes\" if keyword is missing.\n            \n    last_question = observation.questions[-1]\n\n    try:\n        responses = []\n        for i in range(5):\n            response = generate_text_short(\n                f\"\"\"\\\n                Answer yes/no for this keyword: {observation.keyword}\n                Question: {last_question}\n\n                Rules:\n                1. Only consider your keyword: {observation.keyword}\n                2. Think about the context of your keyword and the question asked about it.\n                3. Answer only 'yes' or 'no'\n                Your answer:\n                \"\"\"\n            ).strip().lower() \n            if response in {\"yes\", \"no\"}:\n                responses.append(response)\n            else:\n                if DEBUG:\n                    print(f\"DEBUG____INVALID ANSWER (ANSWERER): '{response}'\")\n\n        if DEBUG:\n            print(\"DEBUG____ALL ANSWERS (ANSWERER): \", responses)\n\n        if responses:\n            return max(set(responses), key=responses.count)\n        else:\n            return \"yes\"\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\", file=sys.stderr)\n        return \"yes\"\n    \n# =========================GUESS AGENT=========================\n\ndef guess(observation: Observation) -> str:\n\n    try:\n        branch = determine_branch(observation)\n        hx_text = assess_history_for_guess(branch, observation)\n        if DEBUG:\n            print(\"DEBUG____ASSESS FOR HISTORY PROMPT (GUESSER): \", hx_text)\n        hx_text = generate_text_long(hx_text)\n        thinking_text = thinking_for_guess(hx_text)\n        if DEBUG:\n            print(\"DEBUG_____THINKING PROMPT (GUESSER): \", thinking_text)\n        thinking_text = generate_text_long(thinking_text)\n        response = thinking_text.lower()\n        guess = parse_guess(response)\n        if DEBUG:\n            print(\"DEBUG____GUESS PARSE PROMPT (GUESSER): \", guess)\n        guess = parse_response_generation(guess)\n        return guess\n    except Exception as e:\n        print(f\"Error while making guess: {e}\")\n        return 'france'\n    \ndef assess_history_for_guess(branch, observation):\n    prompt = f\"\"\"\n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n    {observation.get_history_as_xml(skip_guesses=False)}\n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the previous incorrect guesses, if any. We know that these are incorrect since the game is still in progress.\n    - We know the the keyword is a {branch} based on the questions asked and the answers provided. What specific {branch} is the keyword?\n    - List 10 possible keywords that could be the secret keyword at the end. In early game, it could be anything but as the game progresses, the list should be narrowed down.\n    - Make sure the keywords are specific and not too general. If you only have limited information, make wild guesses.\n    \"\"\"\n    return prompt\n\ndef thinking_for_guess(hx_text):\n    prompt = f\"\"\"\n    You are thinking about what specific guess to make next. You have the following information to consider:\n    \n    {hx_text}\n\n    Based on the information above, what is the best guess you can make? You are required to make a guess, regardless of little information.\n    Your response should start with your reasoning, then you say therefore my next guess is:\n    \"\"\"\n    return prompt\n\ndef parse_guess(response:str) -> str:\n    prompt = f\"\"\"\n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"{response}\"\n\n    Reply with the word or phrase that is the guess here:\n    \"\"\"\n    return prompt\n\n# =========================GENERATE TEXT=========================\n\ndef generate_text_long(prompt:str) -> str:\n    global model_initialized\n    if not model_initialized:\n        initialize_model(model, tokenizer, device=device)\n    sys_prompt = system_message\n    messages = [\n        {\"role\": \"system\", \"content\": sys_prompt},\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\", truncation=True).to(device)\n    generated_ids = model.generate(inputs.input_ids, max_new_tokens=500, temperature=0.75, do_sample=True)\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)]\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    if DEBUG:\n        print(\"DEBUG____GENERATED TEXT LONG (GENERATOR): \", response)\n    return response\n\ndef generate_text_short(prompt:str) -> str:\n    global model_initialized\n    if not model_initialized:\n        initialize_model(model, tokenizer, device=device)\n    sys_prompt = system_message\n    messages = [\n        {\"role\": \"system\", \"content\": sys_prompt},\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\", truncation=True).to(device)\n    generated_ids = model.generate(inputs.input_ids, max_new_tokens=150, temperature=0.4, do_sample=True)\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)]\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    if DEBUG:\n        print(\"DEBUG____GENERATED TEXT SHORT (GENERATOR): \", response)\n    return response\n    \ndef parse_response_generation(prompt:str) -> str:\n    global model_initialized\n    if not model_initialized:\n        initialize_model(model, tokenizer, device=device)\n    messages = [\n        {\"role\": \"system\", \"content\": \"Your role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.\"},\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\", truncation=True).to(device)\n    if DEBUG:\n        print(\"DEBUG____GENERATED PARSE INPUTS (GENERATOR): \", text)\n    generated_ids = model.generate(inputs.input_ids, max_new_tokens=30, temperature=0.1, do_sample=True)\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, generated_ids)]\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    if DEBUG:\n        print(\"DEBUG____GENERATED PARSE RESPONSE (GENERATOR): \", response)\n    return response\n\nagent = None\n\ndef observe(obs: t.Any) -> str:\n    global agent\n    observation = Observation(**obs.__dict__)\n\n    try:\n        match observation.turnType:\n            case \"ask\":\n                agent = ask(observation)\n                return agent\n            case \"answer\":\n                agent = answer(observation)\n                return agent\n            case \"guess\":\n                agent = guess(observation)\n                return agent\n\n            case _:\n                raise ValueError(\"Unknown turn type\")\n    except Exception as e:\n        print(str(e), file=sys.stderr)\n        raise\n\ndef agent_fn(obs: t.Any, _: t.Any) -> str:\n    return observe(obs)\n\n# =========================ENABLE TORCH BACKEND===========================\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:35:38.653963Z","iopub.execute_input":"2024-07-08T11:35:38.654299Z","iopub.status.idle":"2024-07-08T11:35:42.768903Z","shell.execute_reply.started":"2024-07-08T11:35:38.654275Z","shell.execute_reply":"2024-07-08T11:35:42.767480Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd4328be58740d7a5977ea0e2a0d146"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKAGGLE_AGENT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(KAGGLE_AGENT_PATH)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3754\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3745\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3747\u001b[0m     (\n\u001b[1;32m   3748\u001b[0m         model,\n\u001b[1;32m   3749\u001b[0m         missing_keys,\n\u001b[1;32m   3750\u001b[0m         unexpected_keys,\n\u001b[1;32m   3751\u001b[0m         mismatched_keys,\n\u001b[1;32m   3752\u001b[0m         offload_index,\n\u001b[1;32m   3753\u001b[0m         error_msgs,\n\u001b[0;32m-> 3754\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3761\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3765\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3766\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3774\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4214\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4210\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4211\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4212\u001b[0m                 )\n\u001b[1;32m   4213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4214\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4215\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4216\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4221\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4222\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4229\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4231\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:887\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    876\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m ):\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    889\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:400\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 400\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 14.74 GiB of which 38.12 MiB is free. Process 3664 has 14.70 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 132.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 14.74 GiB of which 38.12 MiB is free. Process 3664 has 14.70 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 132.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"markdown","source":"# Submission\nUncomment for submission to Kaggle","metadata":{}},{"cell_type":"code","source":"# !apt install pigz pv","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:17:50.546748Z","iopub.execute_input":"2024-07-08T11:17:50.547261Z","iopub.status.idle":"2024-07-08T11:17:51.247039Z","shell.execute_reply.started":"2024-07-08T11:17:50.547213Z","shell.execute_reply":"2024-07-08T11:17:51.245924Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# !tar --use-compress-program='pigz --fast' \\\n#      -cf submission.tar.gz \\\n#      -C /kaggle/working main.py \\\n#      -C /tmp/submission/ \\\n#      .","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:17:51.248371Z","iopub.execute_input":"2024-07-08T11:17:51.248741Z","iopub.status.idle":"2024-07-08T11:17:51.322161Z","shell.execute_reply.started":"2024-07-08T11:17:51.248707Z","shell.execute_reply":"2024-07-08T11:17:51.321192Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation and Debugging","metadata":{}},{"cell_type":"code","source":"import requests\nimport json\nimport re\n\n# Fetching latest public keywords list from the Kaggle repository\nurl = \"https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py\"\nresponse = requests.get(url)\n\nif response.status_code == 200:\n    match = re.search(r'KEYWORDS_JSON = \"\"\"(.*?)\"\"\"', response.text, re.DOTALL)\n    if match:\n        json_str = match.group(1)\n        keywords_dict = json.loads(json_str)\n    else:\n        print(\"Could not find the KEYWORDS_JSON variable in the file.\")\nelse:\n    print(\"Request failed with status code:\", response.status_code)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:17:51.323232Z","iopub.execute_input":"2024-07-08T11:17:51.325067Z","iopub.status.idle":"2024-07-08T11:17:51.546092Z","shell.execute_reply.started":"2024-07-08T11:17:51.325041Z","shell.execute_reply":"2024-07-08T11:17:51.545069Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import time\nimport typing as t\nimport random\n\ndef select_random_keyword(keywords_dict: t.List[dict]) -> str:\n    category = random.choice(keywords_dict)\n    keyword_dict = random.choice(category['words'])\n    return keyword_dict['keyword'].lower()\n\nDEBUG = input(\"Enable verbose debug mode? (y/n) \") == 'y'\n\nclass MockObservation:\n    def __init__(self, step: int, role: str, turnType: str, keyword: str, category: str, questions: list[str], answers: list[str], guesses: list[str]):\n        self.step = step\n        self.role = role\n        self.turnType = turnType\n        self.keyword = keyword\n        self.category = category\n        self.questions = questions\n        self.answers = answers\n        self.guesses = guesses\n\ndef test_20_questions():\n    global DEBUG\n    step = 0\n    role = \"answerer\"\n    turnType = \"ask\"\n    keyword = select_random_keyword(keywords_dict)\n    print(\"Secret Keyword:\", keyword)\n    category = \"\"\n    questions = []\n    answers = []\n    guesses = []\n    print(\"Starting 20 questions eval game...\")\n    print(\"Keyword:\", keyword)\n    \n    for i in range(60):\n        obs = MockObservation(step, role, turnType, keyword, category, questions, answers, guesses)\n        \n        start_time = time.time()\n        response = agent_fn(obs, None)\n        end_time = time.time()\n        \n        response_time = end_time - start_time\n        \n        # Record the response in the appropriate list\n        if turnType == 'ask':\n            questions.append(response)\n            turnType = 'answer'\n        elif turnType == 'answer':\n            answers.append(response)\n            turnType = 'guess'\n        elif turnType == 'guess':\n            guesses.append(response)\n            if response.lower() == keyword.lower():\n                print(f\"Keyword '{keyword}' guessed correctly! Ending game.\")\n                break\n            turnType = 'ask'\n            step += 1\n            role = 'guesser' if role == 'answerer' else 'answerer'\n        \n        print(f\"{response} {response_time:.2f} sec\")\n    print(\"Secret Keyword:\", keyword)\n    print(\"Final Questions:\", questions)\n    print(\"Final Answers:\", answers)\n    print(\"Final Guesses:\", guesses)\n\n# Run the test\ntest_20_questions()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:28:38.057503Z","iopub.execute_input":"2024-07-08T11:28:38.057886Z","iopub.status.idle":"2024-07-08T11:32:00.171062Z","shell.execute_reply.started":"2024-07-08T11:28:38.057838Z","shell.execute_reply":"2024-07-08T11:32:00.169525Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdin","text":"Enable verbose debug mode? (y/n)  y\n"},{"name":"stdout","text":"Secret Keyword: shanghai china\nStarting 20 questions eval game...\nKeyword: shanghai china\nIs the secret keyword a place? 0.00 sec\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____ALL ANSWERS (ANSWERER):  ['yes', 'yes', 'yes', 'yes', 'yes']\nyes 3.06 sec\nDEBUG____ASSESS FOR HISTORY PROMPT (GUESSER):  \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: [none]\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the previous incorrect guesses, if any. We know that these are incorrect since the game is still in progress.\n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    - List 10 possible keywords that could be the secret keyword at the end. In early game, it could be anything but as the game progresses, the list should be narrowed down.\n    - Make sure the keywords are specific and not too general. If you only have limited information, make wild guesses.\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Known about the keyword:\n- The keyword is a specific place.\n\nUnknown about the keyword:\n- The exact name of the place.\n\nPrevious incorrect guesses:\n- Not applicable, as no guesses have been made yet.\n\nSpecific place as the keyword:\n- The exact name of the place cannot be determined yet.\n\n10 possible keywords (early guesses):\n1. Paris\n2. Tokyo\n3. New York\n4. Cairo\n5. Sydney\n6. Venice\n7. Rome\n8. Cape Town\n9. Mumbai\n10. Toronto\n\nThese are generic place names that have a high likelihood of being recognized by someone. As the game progresses, the list should become more specific.\nDEBUG_____THINKING PROMPT (GUESSER):  \n    You are thinking about what specific guess to make next. You have the following information to consider:\n    \n    Known about the keyword:\n- The keyword is a specific place.\n\nUnknown about the keyword:\n- The exact name of the place.\n\nPrevious incorrect guesses:\n- Not applicable, as no guesses have been made yet.\n\nSpecific place as the keyword:\n- The exact name of the place cannot be determined yet.\n\n10 possible keywords (early guesses):\n1. Paris\n2. Tokyo\n3. New York\n4. Cairo\n5. Sydney\n6. Venice\n7. Rome\n8. Cape Town\n9. Mumbai\n10. Toronto\n\nThese are generic place names that have a high likelihood of being recognized by someone. As the game progresses, the list should become more specific.\n\n    Based on the information above, what is the best guess you can make? You are required to make a guess, regardless of little information.\n    Your response should start with your reasoning, then you say therefore my next guess is:\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Based on the information provided, the best initial guess would be one that is a commonly known and specific place, which has a high chance of being recognized by a wide audience. Given the options, Paris and New York are among the most well-known cities globally, and they both fit the criteria of being specific places. Since the keyword is not yet determined, it would be wise to choose a city that is widely recognized across various cultures and continents.\n\nTherefore, my next guess is Paris.\nDEBUG____GUESS PARSE PROMPT (GUESSER):  \n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"based on the information provided, the best initial guess would be one that is a commonly known and specific place, which has a high chance of being recognized by a wide audience. given the options, paris and new york are among the most well-known cities globally, and they both fit the criteria of being specific places. since the keyword is not yet determined, it would be wise to choose a city that is widely recognized across various cultures and continents.\n\ntherefore, my next guess is paris.\"\n\n    Reply with the word or phrase that is the guess here:\n    \nDEBUG____GENERATED PARSE INPUTS (GENERATOR):  <|system|>\nYour role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.<|end|>\n<|user|>\n\n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"based on the information provided, the best initial guess would be one that is a commonly known and specific place, which has a high chance of being recognized by a wide audience. given the options, paris and new york are among the most well-known cities globally, and they both fit the criteria of being specific places. since the keyword is not yet determined, it would be wise to choose a city that is widely recognized across various cultures and continents.\n\ntherefore, my next guess is paris.\"\n\n    Reply with the word or phrase that is the guess here:\n    <|end|>\n<|assistant|>\n\nDEBUG____GENERATED PARSE RESPONSE (GENERATOR):  paris\nparis 14.61 sec\nIs it in the western hemisphere? 0.00 sec\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  No\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  No\nDEBUG____ALL ANSWERS (ANSWERER):  ['no', 'no', 'no', 'no', 'no']\nno 3.04 sec\nDEBUG____ASSESS FOR HISTORY PROMPT (GUESSER):  \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: paris\n            \n            Question: Is it in the western hemisphere?\n            Answer: no\n            Guess: [none]\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the previous incorrect guesses, if any. We know that these are incorrect since the game is still in progress.\n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    - List 10 possible keywords that could be the secret keyword at the end. In early game, it could be anything but as the game progresses, the list should be narrowed down.\n    - Make sure the keywords are specific and not too general. If you only have limited information, make wild guesses.\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Based on the provided game history, here is a summary of what is known and not known about the keyword:\n\n**Known about the keyword:**\n- The keyword is a specific place.\n- It is not in the western hemisphere.\n\n**Not known about the keyword:**\n- The exact name of the place.\n- The geographical location beyond that it is not in the western hemisphere.\n\n**Previous incorrect guesses:**\n- Paris\n\n**Specific place based on questions and answers:**\n- At this point, it is impossible to determine the specific place without additional questions.\n\n**List of 10 possible keywords that could be the secret keyword at the end:**\nGiven that the keyword is a specific place and not in the western hemisphere, some potential possibilities could be:\n\n1. Beijing, China\n2. Tokyo, Japan\n3. New Delhi, India\n4. Seoul, South Korea\n5. Mumbai, India\n6. Jakarta, Indonesia\n7. Moscow, Russia\n8. Beijing, China\n9. Buenos Aires, Argentina\n10. Brasília, Brazil\n\nThese possibilities cover various cities in Asia, Eastern Europe, and South America. Additional questions would narrow down the options to a more specific place.\nDEBUG_____THINKING PROMPT (GUESSER):  \n    You are thinking about what specific guess to make next. You have the following information to consider:\n    \n    Based on the provided game history, here is a summary of what is known and not known about the keyword:\n\n**Known about the keyword:**\n- The keyword is a specific place.\n- It is not in the western hemisphere.\n\n**Not known about the keyword:**\n- The exact name of the place.\n- The geographical location beyond that it is not in the western hemisphere.\n\n**Previous incorrect guesses:**\n- Paris\n\n**Specific place based on questions and answers:**\n- At this point, it is impossible to determine the specific place without additional questions.\n\n**List of 10 possible keywords that could be the secret keyword at the end:**\nGiven that the keyword is a specific place and not in the western hemisphere, some potential possibilities could be:\n\n1. Beijing, China\n2. Tokyo, Japan\n3. New Delhi, India\n4. Seoul, South Korea\n5. Mumbai, India\n6. Jakarta, Indonesia\n7. Moscow, Russia\n8. Beijing, China\n9. Buenos Aires, Argentina\n10. Brasília, Brazil\n\nThese possibilities cover various cities in Asia, Eastern Europe, and South America. Additional questions would narrow down the options to a more specific place.\n\n    Based on the information above, what is the best guess you can make? You are required to make a guess, regardless of little information.\n    Your response should start with your reasoning, then you say therefore my next guess is:\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Given the information provided, the best guess at this stage would be a city in Asia since it is a specific place not in the western hemisphere. Considering the list of 10 possible keywords, I will eliminate Tokyo, Japan, and Buenos Aires, Argentina, because I am not provided with any hints that could help guess these cities. This leaves us with 7 possible cities.\n\nBased on the previous incorrect guess of Paris, it's evident that European cities are not the secret keyword. Therefore, I will focus on cities from Asia, Eastern Europe, and South America. The cities left after considering the mentioned guesses are:\n\n1. Beijing, China\n2. New Delhi, India\n3. Seoul, South Korea\n4. Mumbai, India\n5. Jakarta, Indonesia\n6. Moscow, Russia\n7. Brasília, Brazil\n\nOut of this remaining list, the top choices for cities in Asia or Eastern Europe still are Beijing, China, New Delhi, India, Seoul, South Korea, and Moscow, Russia. Since Brazilian cities are not mentioned as part of the known location (not in the western hemisphere), Brasília can be eliminated.\n\nConsidering the remaining cities, Beijing, China, and Moscow, Russia, have a higher population compared to the others. In the context of guessing a place, people might be more familiar with these cities. However, it's also important to note that Mumbai, India, and Jakarta, Indonesia, represent significant cultural and economic hubs.\n\nTherefore, my next guess is:\n\nBeijing, China.\nDEBUG____GUESS PARSE PROMPT (GUESSER):  \n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"given the information provided, the best guess at this stage would be a city in asia since it is a specific place not in the western hemisphere. considering the list of 10 possible keywords, i will eliminate tokyo, japan, and buenos aires, argentina, because i am not provided with any hints that could help guess these cities. this leaves us with 7 possible cities.\n\nbased on the previous incorrect guess of paris, it's evident that european cities are not the secret keyword. therefore, i will focus on cities from asia, eastern europe, and south america. the cities left after considering the mentioned guesses are:\n\n1. beijing, china\n2. new delhi, india\n3. seoul, south korea\n4. mumbai, india\n5. jakarta, indonesia\n6. moscow, russia\n7. brasília, brazil\n\nout of this remaining list, the top choices for cities in asia or eastern europe still are beijing, china, new delhi, india, seoul, south korea, and moscow, russia. since brazilian cities are not mentioned as part of the known location (not in the western hemisphere), brasília can be eliminated.\n\nconsidering the remaining cities, beijing, china, and moscow, russia, have a higher population compared to the others. in the context of guessing a place, people might be more familiar with these cities. however, it's also important to note that mumbai, india, and jakarta, indonesia, represent significant cultural and economic hubs.\n\ntherefore, my next guess is:\n\nbeijing, china.\"\n\n    Reply with the word or phrase that is the guess here:\n    \nDEBUG____GENERATED PARSE INPUTS (GENERATOR):  <|system|>\nYour role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.<|end|>\n<|user|>\n\n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"given the information provided, the best guess at this stage would be a city in asia since it is a specific place not in the western hemisphere. considering the list of 10 possible keywords, i will eliminate tokyo, japan, and buenos aires, argentina, because i am not provided with any hints that could help guess these cities. this leaves us with 7 possible cities.\n\nbased on the previous incorrect guess of paris, it's evident that european cities are not the secret keyword. therefore, i will focus on cities from asia, eastern europe, and south america. the cities left after considering the mentioned guesses are:\n\n1. beijing, china\n2. new delhi, india\n3. seoul, south korea\n4. mumbai, india\n5. jakarta, indonesia\n6. moscow, russia\n7. brasília, brazil\n\nout of this remaining list, the top choices for cities in asia or eastern europe still are beijing, china, new delhi, india, seoul, south korea, and moscow, russia. since brazilian cities are not mentioned as part of the known location (not in the western hemisphere), brasília can be eliminated.\n\nconsidering the remaining cities, beijing, china, and moscow, russia, have a higher population compared to the others. in the context of guessing a place, people might be more familiar with these cities. however, it's also important to note that mumbai, india, and jakarta, indonesia, represent significant cultural and economic hubs.\n\ntherefore, my next guess is:\n\nbeijing, china.\"\n\n    Reply with the word or phrase that is the guess here:\n    <|end|>\n<|assistant|>\n\nDEBUG____GENERATED PARSE RESPONSE (GENERATOR):  beijing china\nbeijing china 31.94 sec\nIs the place natural and not man-made? 0.00 sec\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  No\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  no\nDEBUG____ALL ANSWERS (ANSWERER):  ['no', 'no', 'no', 'no', 'no']\nno 3.18 sec\nDEBUG____ASSESS FOR HISTORY PROMPT (GUESSER):  \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: paris\n            \n            Question: Is it in the western hemisphere?\n            Answer: no\n            Guess: beijing china\n            \n            Question: Is the place natural and not man-made?\n            Answer: no\n            Guess: [none]\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the previous incorrect guesses, if any. We know that these are incorrect since the game is still in progress.\n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    - List 10 possible keywords that could be the secret keyword at the end. In early game, it could be anything but as the game progresses, the list should be narrowed down.\n    - Make sure the keywords are specific and not too general. If you only have limited information, make wild guesses.\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  - Known about the keyword:\n  - The keyword is a place.\n  - It is not in the western hemisphere.\n  - It is not a natural, non-man-made place.\n\n- Unknown about the keyword:\n  - The exact name of the place.\n  - The specific region or country it belongs to within the non-western hemisphere.\n  - Any particular attributes or characteristics of the place.\n\n- Previous incorrect guesses:\n  1. Paris\n  2. Beijing, China\n\n- What specific place could be the keyword?\n  - Without further information, it's impossible to accurately determine the specific place. However, some possible guesses, based on the information provided, might include:\n    1. Tokyo, Japan\n    2. New Delhi, India\n    3. Moscow, Russia\n    4. Seoul, South Korea\n    5. Bangkok, Thailand\n    6. Jakarta, Indonesia\n    7. Manila, Philippines\n    8. Cairo, Egypt\n    9. Canberra, Australia (Australia is in the eastern hemisphere and contains non-natural, man-made places.)\n    10. Wellington, New Zealand (New Zealand is in the eastern hemisphere but can sometimes be considered part of the western hemisphere due to its proximity to the International Date Line.)\n\n- Ten possible keywords that could be the secret keyword, considering non-western hemisphere, man-made places, and specific locations within those regions:\n  1. Tokyo, Japan - as a major city, and a non-western hemisphere location.\n  2. New Delhi, India - known for being the capital city.\n  3. Moscow, Russia - a major global city.\n  4. Seoul, South Korea - a major city in Asia.\n  5. Bangkok, Thailand - a key city in Southeast Asia.\n  6. Jakarta, Indonesia - the capital city of Indonesia.\n  7. Manila, Philippines - one of the Philippine archipelago's biggest cities.\n  8. Cairo, Egypt - the capital city of Egypt.\n  9. Canberra, Australia - the capital city of Australia.\n  \nDEBUG_____THINKING PROMPT (GUESSER):  \n    You are thinking about what specific guess to make next. You have the following information to consider:\n    \n    - Known about the keyword:\n  - The keyword is a place.\n  - It is not in the western hemisphere.\n  - It is not a natural, non-man-made place.\n\n- Unknown about the keyword:\n  - The exact name of the place.\n  - The specific region or country it belongs to within the non-western hemisphere.\n  - Any particular attributes or characteristics of the place.\n\n- Previous incorrect guesses:\n  1. Paris\n  2. Beijing, China\n\n- What specific place could be the keyword?\n  - Without further information, it's impossible to accurately determine the specific place. However, some possible guesses, based on the information provided, might include:\n    1. Tokyo, Japan\n    2. New Delhi, India\n    3. Moscow, Russia\n    4. Seoul, South Korea\n    5. Bangkok, Thailand\n    6. Jakarta, Indonesia\n    7. Manila, Philippines\n    8. Cairo, Egypt\n    9. Canberra, Australia (Australia is in the eastern hemisphere and contains non-natural, man-made places.)\n    10. Wellington, New Zealand (New Zealand is in the eastern hemisphere but can sometimes be considered part of the western hemisphere due to its proximity to the International Date Line.)\n\n- Ten possible keywords that could be the secret keyword, considering non-western hemisphere, man-made places, and specific locations within those regions:\n  1. Tokyo, Japan - as a major city, and a non-western hemisphere location.\n  2. New Delhi, India - known for being the capital city.\n  3. Moscow, Russia - a major global city.\n  4. Seoul, South Korea - a major city in Asia.\n  5. Bangkok, Thailand - a key city in Southeast Asia.\n  6. Jakarta, Indonesia - the capital city of Indonesia.\n  7. Manila, Philippines - one of the Philippine archipelago's biggest cities.\n  8. Cairo, Egypt - the capital city of Egypt.\n  9. Canberra, Australia - the capital city of Australia.\n  \n\n    Based on the information above, what is the best guess you can make? You are required to make a guess, regardless of little information.\n    Your response should start with your reasoning, then you say therefore my next guess is:\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Based on the information provided, the best guess I can make for the secret keyword is \"Seoul, South Korea\". My reasoning is as follows:\n\n- The keyword is a place and not in the western hemisphere.\n- It is not a natural, non-man-made place.\n- Previous incorrect guesses include Paris and Beijing, China, which are in the western hemisphere.\n- Tokyo, New Delhi, Moscow, Bangkok, Jakarta, Manila, and Cairo are all in the eastern hemisphere and are man-made places.\n- Canberra was suggested, but it is in Australia which has been considered part of the western hemisphere due to its proximity to the International Date Line.\n\nConsidering these factors, Seoul, South Korea, meets all the requirements: it's in the eastern hemisphere, it's a man-made place as a capital city, and none of the previous guesses have been in the eastern hemisphere. Therefore, my next guess is: Seoul, South Korea.\nDEBUG____GUESS PARSE PROMPT (GUESSER):  \n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"based on the information provided, the best guess i can make for the secret keyword is \"seoul, south korea\". my reasoning is as follows:\n\n- the keyword is a place and not in the western hemisphere.\n- it is not a natural, non-man-made place.\n- previous incorrect guesses include paris and beijing, china, which are in the western hemisphere.\n- tokyo, new delhi, moscow, bangkok, jakarta, manila, and cairo are all in the eastern hemisphere and are man-made places.\n- canberra was suggested, but it is in australia which has been considered part of the western hemisphere due to its proximity to the international date line.\n\nconsidering these factors, seoul, south korea, meets all the requirements: it's in the eastern hemisphere, it's a man-made place as a capital city, and none of the previous guesses have been in the eastern hemisphere. therefore, my next guess is: seoul, south korea.\"\n\n    Reply with the word or phrase that is the guess here:\n    \nDEBUG____GENERATED PARSE INPUTS (GENERATOR):  <|system|>\nYour role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.<|end|>\n<|user|>\n\n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"based on the information provided, the best guess i can make for the secret keyword is \"seoul, south korea\". my reasoning is as follows:\n\n- the keyword is a place and not in the western hemisphere.\n- it is not a natural, non-man-made place.\n- previous incorrect guesses include paris and beijing, china, which are in the western hemisphere.\n- tokyo, new delhi, moscow, bangkok, jakarta, manila, and cairo are all in the eastern hemisphere and are man-made places.\n- canberra was suggested, but it is in australia which has been considered part of the western hemisphere due to its proximity to the international date line.\n\nconsidering these factors, seoul, south korea, meets all the requirements: it's in the eastern hemisphere, it's a man-made place as a capital city, and none of the previous guesses have been in the eastern hemisphere. therefore, my next guess is: seoul, south korea.\"\n\n    Reply with the word or phrase that is the guess here:\n    <|end|>\n<|assistant|>\n\nDEBUG____GENERATED PARSE RESPONSE (GENERATOR):  seoul south korea\nseoul south korea 36.55 sec\nDEBUG_____ASSESS HISTROY PROMPT (QUESTIONER) \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: paris\n            \n            Question: Is it in the western hemisphere?\n            Answer: no\n            Guess: beijing china\n            \n            Question: Is the place natural and not man-made?\n            Answer: no\n            Guess: seoul south korea\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the incorrect guesses, if any. We know that these are incorrect since the game is still in progress. \n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Known about the keyword:\n- The keyword is a place\n- It is not in the western hemisphere\n- The place is man-made and not natural\n\nNot known about the keyword:\n- The specific country or city where the keyword is located\n- The region or continent where the keyword is located\n- The exact name of the place (e.g., city, country)\n- The culture, language, or other characteristics associated with the keyword\n\nIncorrect guesses:\n- Paris, France\n- Beijing, China\n- Seoul, South Korea\n\nSince the game is still in progress, we can't make a definitive list of incorrect guesses. However, Paris, Beijing, and Seoul were the guesses provided in the game history.\nDEBUG_____THINKING PROMPT (QUESTIONER) \n    You are thinking about what question to ask next. You have the following information to consider:\n    \n    Known about the keyword:\n- The keyword is a place\n- It is not in the western hemisphere\n- The place is man-made and not natural\n\nNot known about the keyword:\n- The specific country or city where the keyword is located\n- The region or continent where the keyword is located\n- The exact name of the place (e.g., city, country)\n- The culture, language, or other characteristics associated with the keyword\n\nIncorrect guesses:\n- Paris, France\n- Beijing, China\n- Seoul, South Korea\n\nSince the game is still in progress, we can't make a definitive list of incorrect guesses. However, Paris, Beijing, and Seoul were the guesses provided in the game history.\n\n    Based on the information above, what is the next question you would like to ask to bisect the search space and narrow down the possibilities?\n    If categories are still unclear, it may be best to ask a yes/no question that narrows the known category down further. You are not allowed to ask questions that are not yes/no.\n    Your response should start with your reasoning, then you say therefore my next quesiton is:\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Based on the given information, we know that the keyword is a man-made place located outside of the western hemisphere. To bisect the search space and narrow down the possibilities, I would like to ask the following question:\n\nIs the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the western hemisphere, it must be located either in the eastern hemisphere or the southern hemisphere. By dividing the search space into these two categories, we can further narrow down the possibilities and make it easier to guess the correct keyword. This question can be answered with a simple \"yes\" or \"no\", which adheres to the constraints of the game.\nDEBUG_____QUESTION PASRING PROMPT (QUESTIONER) Based on the given information, we know that the keyword is a man-made place located outside of the western hemisphere. To bisect the search space and narrow down the possibilities, I would like to ask the following question:\n\nIs the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the western hemisphere, it must be located either in the eastern hemisphere or the southern hemisphere. By dividing the search space into these two categories, we can further narrow down the possibilities and make it easier to guess the correct keyword. This question can be answered with a simple \"yes\" or \"no\", which adheres to the constraints of the game.\nDEBUG____GENERATED PARSE INPUTS (GENERATOR):  <|system|>\nYour role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.<|end|>\n<|user|>\nBased on the given information, we know that the keyword is a man-made place located outside of the western hemisphere. To bisect the search space and narrow down the possibilities, I would like to ask the following question:\n\nIs the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the western hemisphere, it must be located either in the eastern hemisphere or the southern hemisphere. By dividing the search space into these two categories, we can further narrow down the possibilities and make it easier to guess the correct keyword. This question can be answered with a simple \"yes\" or \"no\", which adheres to the constraints of the game.<|end|>\n<|assistant|>\n\nDEBUG____GENERATED PARSE RESPONSE (GENERATOR):  Is the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the\nIs the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the 18.38 sec\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  yes\n\nReasoning: Shanghai is a city located in China, which is in the Eastern Hemisphere.\nDEBUG____INVALID ANSWER (ANSWERER): 'yes\n\nreasoning: shanghai is a city located in china, which is in the eastern hemisphere.'\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\n\nReasoning: Shanghai is a city located in China, which is in the Eastern Hemisphere. It is not in the Southern Hemisphere.\nDEBUG____INVALID ANSWER (ANSWERER): 'yes\n\nreasoning: shanghai is a city located in china, which is in the eastern hemisphere. it is not in the southern hemisphere.'\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\n\nReasoning: Shanghai is a city in China, which is located in the Eastern Hemisphere. The Southern Hemisphere refers to the half of Earth that is south of the Equator. Shanghai, being in the Northern Hemisphere, is not in the Southern Hemisphere.\nDEBUG____INVALID ANSWER (ANSWERER): 'yes\n\nreasoning: shanghai is a city in china, which is located in the eastern hemisphere. the southern hemisphere refers to the half of earth that is south of the equator. shanghai, being in the northern hemisphere, is not in the southern hemisphere.'\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\n\nReasoning: Shanghai is a city located in China, which is in the Eastern Hemisphere. The Southern Hemisphere refers to the half of Earth that is south of the equator. Since Shanghai is in the Northern Hemisphere, the answer is 'yes' it is located in the Eastern Hemisphere.\nDEBUG____INVALID ANSWER (ANSWERER): 'yes\n\nreasoning: shanghai is a city located in china, which is in the eastern hemisphere. the southern hemisphere refers to the half of earth that is south of the equator. since shanghai is in the northern hemisphere, the answer is 'yes' it is located in the eastern hemisphere.'\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  yes\n\nReasoning: Shanghai is a city in China, and both China and the city of Shanghai are located in the Eastern Hemisphere, not the Southern Hemisphere.\nDEBUG____INVALID ANSWER (ANSWERER): 'yes\n\nreasoning: shanghai is a city in china, and both china and the city of shanghai are located in the eastern hemisphere, not the southern hemisphere.'\nDEBUG____ALL ANSWERS (ANSWERER):  []\nyes 13.80 sec\nDEBUG____ASSESS FOR HISTORY PROMPT (GUESSER):  \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: paris\n            \n            Question: Is it in the western hemisphere?\n            Answer: no\n            Guess: beijing china\n            \n            Question: Is the place natural and not man-made?\n            Answer: no\n            Guess: seoul south korea\n            \n            Question: Is the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the\n            Answer: yes\n            Guess: [none]\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the previous incorrect guesses, if any. We know that these are incorrect since the game is still in progress.\n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    - List 10 possible keywords that could be the secret keyword at the end. In early game, it could be anything but as the game progresses, the list should be narrowed down.\n    - Make sure the keywords are specific and not too general. If you only have limited information, make wild guesses.\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Known about the keyword:\n- The keyword is a place\n- It is not in the Western Hemisphere\n- It is not a natural, man-made place\n- It is located in either the Eastern Hemisphere or the Southern Hemisphere\n\nNot known about the keyword:\n- The specific country, city, or region\n- The geographical location (Eastern or Southern Hemisphere)\n- If it is a city, country, or region\n- Other details such as climate, culture, or landmarks\n\nPrevious incorrect guesses:\n- Paris\n- Beijing, China\n- Seoul, South Korea\n\nThe specific place cannot be determined based on the given questions and answers.\n\nPossible keywords (10):\n1. Tokyo, Japan\n2. Sydney, Australia\n3. Cairo, Egypt\n4. Buenos Aires, Argentina\n5. Dubai, United Arab Emirates\n6. Bangkok, Thailand\n7. Cape Town, South Africa\n8. Lisbon, Portugal\n9. Rio de Janeiro, Brazil\n10. Moscow, Russia\n\nAs the game progresses, the list should be narrowed down based on the elimination of incorrect guesses and considering the clues from the questions and answers.\nDEBUG_____THINKING PROMPT (GUESSER):  \n    You are thinking about what specific guess to make next. You have the following information to consider:\n    \n    Known about the keyword:\n- The keyword is a place\n- It is not in the Western Hemisphere\n- It is not a natural, man-made place\n- It is located in either the Eastern Hemisphere or the Southern Hemisphere\n\nNot known about the keyword:\n- The specific country, city, or region\n- The geographical location (Eastern or Southern Hemisphere)\n- If it is a city, country, or region\n- Other details such as climate, culture, or landmarks\n\nPrevious incorrect guesses:\n- Paris\n- Beijing, China\n- Seoul, South Korea\n\nThe specific place cannot be determined based on the given questions and answers.\n\nPossible keywords (10):\n1. Tokyo, Japan\n2. Sydney, Australia\n3. Cairo, Egypt\n4. Buenos Aires, Argentina\n5. Dubai, United Arab Emirates\n6. Bangkok, Thailand\n7. Cape Town, South Africa\n8. Lisbon, Portugal\n9. Rio de Janeiro, Brazil\n10. Moscow, Russia\n\nAs the game progresses, the list should be narrowed down based on the elimination of incorrect guesses and considering the clues from the questions and answers.\n\n    Based on the information above, what is the best guess you can make? You are required to make a guess, regardless of little information.\n    Your response should start with your reasoning, then you say therefore my next guess is:\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Based on the given clues, the best guess can be made by eliminating options that do not fit the provided information. \n\nKnown information:\n- The keyword is a place\n- It is not in the Western Hemisphere\n- It is not a natural, man-made place\n- It is located in either the Eastern or Southern Hemisphere\n\nPrevious incorrect guesses:\n- Paris (Incorrect, in the Western Hemisphere)\n- Beijing, China (Incorrect, in the Eastern Hemisphere)\n- Seoul, South Korea (Incorrect, in the Eastern Hemisphere)\n\nFrom the 10 possible keywords, we can eliminate options that are in the Western Hemisphere (Paris and Lisbon) and the ones in the Eastern Hemisphere but not in the Southern Hemisphere (Tokyo, Moscow, and Dubai).\n\nRemaining options:\n1. Sydney, Australia\n2. Cairo, Egypt\n3. Buenos Aires, Argentina\n4. Cape Town, South Africa\n5. Bangkok, Thailand\n6. Rio de Janeiro, Brazil\n\nConsidering the clues that the keyword is not a natural, man-made place and is located in the Southern Hemisphere, we can eliminate options 2 (Cairo, Egypt), 3 (Buenos Aires, Argentina), and 5 (Bangkok, Thailand).\n\nThe final two options are:\n1. Sydney, Australia (Incorrect, still in the Southern Hemisphere)\n2. Cape Town, South Africa\n\nSince South Africa is in the Southern Hemisphere and it is a man-made place (a city), it fits the given information.\n\nTherefore, my next guess is: Cape Town, South Africa.\nDEBUG____GUESS PARSE PROMPT (GUESSER):  \n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"based on the given clues, the best guess can be made by eliminating options that do not fit the provided information. \n\nknown information:\n- the keyword is a place\n- it is not in the western hemisphere\n- it is not a natural, man-made place\n- it is located in either the eastern or southern hemisphere\n\nprevious incorrect guesses:\n- paris (incorrect, in the western hemisphere)\n- beijing, china (incorrect, in the eastern hemisphere)\n- seoul, south korea (incorrect, in the eastern hemisphere)\n\nfrom the 10 possible keywords, we can eliminate options that are in the western hemisphere (paris and lisbon) and the ones in the eastern hemisphere but not in the southern hemisphere (tokyo, moscow, and dubai).\n\nremaining options:\n1. sydney, australia\n2. cairo, egypt\n3. buenos aires, argentina\n4. cape town, south africa\n5. bangkok, thailand\n6. rio de janeiro, brazil\n\nconsidering the clues that the keyword is not a natural, man-made place and is located in the southern hemisphere, we can eliminate options 2 (cairo, egypt), 3 (buenos aires, argentina), and 5 (bangkok, thailand).\n\nthe final two options are:\n1. sydney, australia (incorrect, still in the southern hemisphere)\n2. cape town, south africa\n\nsince south africa is in the southern hemisphere and it is a man-made place (a city), it fits the given information.\n\ntherefore, my next guess is: cape town, south africa.\"\n\n    Reply with the word or phrase that is the guess here:\n    \nDEBUG____GENERATED PARSE INPUTS (GENERATOR):  <|system|>\nYour role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.<|end|>\n<|user|>\n\n    Your role is to take text below and parse a valid guess for the game of 20 questions. You do not provide extra details. Just the guess based on the text provided.\n    It should be formatted as a guess and have no punctuation. Limit the guess to 50 characters.\n    Here is the text:\n\n    \"based on the given clues, the best guess can be made by eliminating options that do not fit the provided information. \n\nknown information:\n- the keyword is a place\n- it is not in the western hemisphere\n- it is not a natural, man-made place\n- it is located in either the eastern or southern hemisphere\n\nprevious incorrect guesses:\n- paris (incorrect, in the western hemisphere)\n- beijing, china (incorrect, in the eastern hemisphere)\n- seoul, south korea (incorrect, in the eastern hemisphere)\n\nfrom the 10 possible keywords, we can eliminate options that are in the western hemisphere (paris and lisbon) and the ones in the eastern hemisphere but not in the southern hemisphere (tokyo, moscow, and dubai).\n\nremaining options:\n1. sydney, australia\n2. cairo, egypt\n3. buenos aires, argentina\n4. cape town, south africa\n5. bangkok, thailand\n6. rio de janeiro, brazil\n\nconsidering the clues that the keyword is not a natural, man-made place and is located in the southern hemisphere, we can eliminate options 2 (cairo, egypt), 3 (buenos aires, argentina), and 5 (bangkok, thailand).\n\nthe final two options are:\n1. sydney, australia (incorrect, still in the southern hemisphere)\n2. cape town, south africa\n\nsince south africa is in the southern hemisphere and it is a man-made place (a city), it fits the given information.\n\ntherefore, my next guess is: cape town, south africa.\"\n\n    Reply with the word or phrase that is the guess here:\n    <|end|>\n<|assistant|>\n\nDEBUG____GENERATED PARSE RESPONSE (GENERATOR):  Cape Town, South Africa\nCape Town, South Africa 33.09 sec\nDEBUG_____ASSESS HISTROY PROMPT (QUESTIONER) \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: paris\n            \n            Question: Is it in the western hemisphere?\n            Answer: no\n            Guess: beijing china\n            \n            Question: Is the place natural and not man-made?\n            Answer: no\n            Guess: seoul south korea\n            \n            Question: Is the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the\n            Answer: yes\n            Guess: Cape Town, South Africa\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the incorrect guesses, if any. We know that these are incorrect since the game is still in progress. \n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  - Known about the keyword:\n    1. The keyword is a place.\n    2. It is not in the Western Hemisphere.\n    3. It is not a natural, non-man-made location.\n    4. It is located in either the Eastern Hemisphere or the Southern Hemisphere.\n\n- Not known about the keyword:\n    1. The specific country or city it is located in.\n    2. The exact latitude or longitude coordinates.\n    3. The population size or other demographic information.\n    4. Its cultural, historical, or geographical significance.\n\n- Incorrect guesses:\n    1. Paris\n    2. Beijing, China\n    3. Seoul, South Korea\n    4. Cape Town, South Africa\n\n- The specific place the keyword is: Insufficient information to determine the specific place.\nDEBUG_____THINKING PROMPT (QUESTIONER) \n    You are thinking about what question to ask next. You have the following information to consider:\n    \n    - Known about the keyword:\n    1. The keyword is a place.\n    2. It is not in the Western Hemisphere.\n    3. It is not a natural, non-man-made location.\n    4. It is located in either the Eastern Hemisphere or the Southern Hemisphere.\n\n- Not known about the keyword:\n    1. The specific country or city it is located in.\n    2. The exact latitude or longitude coordinates.\n    3. The population size or other demographic information.\n    4. Its cultural, historical, or geographical significance.\n\n- Incorrect guesses:\n    1. Paris\n    2. Beijing, China\n    3. Seoul, South Korea\n    4. Cape Town, South Africa\n\n- The specific place the keyword is: Insufficient information to determine the specific place.\n\n    Based on the information above, what is the next question you would like to ask to bisect the search space and narrow down the possibilities?\n    If categories are still unclear, it may be best to ask a yes/no question that narrows the known category down further. You are not allowed to ask questions that are not yes/no.\n    Your response should start with your reasoning, then you say therefore my next quesiton is:\n    \nDEBUG____GENERATED TEXT LONG (GENERATOR):  Based on the known information, the keyword is a place that is not in the Western Hemisphere, non-natural, and located in either the Eastern or Southern Hemisphere. The incorrect guesses also help narrow down the search space, as they are all cities in the Eastern Hemisphere. \n\nTo further narrow down the possibilities, it would be beneficial to ask a yes/no question that distinguishes between Eastern and Southern Hemisphere locations. A suitable question could be: \"Is the location in the Eastern Hemisphere?\" This will help eliminate the possibility of the keyword being in the Southern Hemisphere, as it is not known if it is in the Eastern Hemisphere.\n\nTherefore, my next question is: \"Is the location in the Eastern Hemisphere?\" This question aims to bisect the search space between the Eastern and Southern Hemispheres to narrow down the possibilities.\nDEBUG_____QUESTION PASRING PROMPT (QUESTIONER) Based on the known information, the keyword is a place that is not in the Western Hemisphere, non-natural, and located in either the Eastern or Southern Hemisphere. The incorrect guesses also help narrow down the search space, as they are all cities in the Eastern Hemisphere. \n\nTo further narrow down the possibilities, it would be beneficial to ask a yes/no question that distinguishes between Eastern and Southern Hemisphere locations. A suitable question could be: \"Is the location in the Eastern Hemisphere?\" This will help eliminate the possibility of the keyword being in the Southern Hemisphere, as it is not known if it is in the Eastern Hemisphere.\n\nTherefore, my next question is: \"Is the location in the Eastern Hemisphere?\" This question aims to bisect the search space between the Eastern and Southern Hemispheres to narrow down the possibilities.\nDEBUG____GENERATED PARSE INPUTS (GENERATOR):  <|system|>\nYour role is to take text and parse a valid question or guess for the game of 20 questions. You do not provide extra details. Just the question or the answer based on the text provided.<|end|>\n<|user|>\nBased on the known information, the keyword is a place that is not in the Western Hemisphere, non-natural, and located in either the Eastern or Southern Hemisphere. The incorrect guesses also help narrow down the search space, as they are all cities in the Eastern Hemisphere. \n\nTo further narrow down the possibilities, it would be beneficial to ask a yes/no question that distinguishes between Eastern and Southern Hemisphere locations. A suitable question could be: \"Is the location in the Eastern Hemisphere?\" This will help eliminate the possibility of the keyword being in the Southern Hemisphere, as it is not known if it is in the Eastern Hemisphere.\n\nTherefore, my next question is: \"Is the location in the Eastern Hemisphere?\" This question aims to bisect the search space between the Eastern and Southern Hemispheres to narrow down the possibilities.<|end|>\n<|assistant|>\n\nDEBUG____GENERATED PARSE RESPONSE (GENERATOR):  Based on the information provided, the keyword is a place that is not in the Western Hemisphere, non-natural, and located in either the\nBased on the information provided, the keyword is a place that is not in the Western Hemisphere, non-natural, and located in either the 20.96 sec\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  Yes\nDEBUG____GENERATED TEXT SHORT (GENERATOR):  yes\nDEBUG____ALL ANSWERS (ANSWERER):  ['yes', 'yes', 'yes', 'yes', 'yes']\nyes 4.04 sec\nDEBUG____ASSESS FOR HISTORY PROMPT (GUESSER):  \n    Your objective is to review the following game history and create a summary of what is known and what is not known about the keyword. The guesses inckuded are not correct, so we are still playing the game.\n    Here is the history:\n\n                Question: Is the secret keyword a place?\n            Answer: yes\n            Guess: paris\n            \n            Question: Is it in the western hemisphere?\n            Answer: no\n            Guess: beijing china\n            \n            Question: Is the place natural and not man-made?\n            Answer: no\n            Guess: seoul south korea\n            \n            Question: Is the keyword located in the Eastern Hemisphere or the Southern Hemisphere?\n\nReasoning: Since the keyword is not in the\n            Answer: yes\n            Guess: Cape Town, South Africa\n            \n            Question: Based on the information provided, the keyword is a place that is not in the Western Hemisphere, non-natural, and located in either the\n            Answer: yes\n            Guess: [none]\n            \n    \n    Now provide the follwing information:\n    - What is known about the keyword?\n    - What is not known about the keyword?\n    - Make a list of the previous incorrect guesses, if any. We know that these are incorrect since the game is still in progress.\n    - We know the the keyword is a place based on the questions asked and the answers provided. What specific place is the keyword?\n    - List 10 possible keywords that could be the secret keyword at the end. In early game, it could be anything but as the game progresses, the list should be narrowed down.\n    - Make sure the keywords are specific and not too general. If you only have limited information, make wild guesses.\n    \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Guesses:\u001b[39m\u001b[38;5;124m\"\u001b[39m, guesses)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mtest_20_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[14], line 41\u001b[0m, in \u001b[0;36mtest_20_questions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m obs \u001b[38;5;241m=\u001b[39m MockObservation(step, role, turnType, keyword, category, questions, answers, guesses)\n\u001b[1;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 41\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     44\u001b[0m response_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n","Cell \u001b[0;32mIn[13], line 374\u001b[0m, in \u001b[0;36magent_fn\u001b[0;34m(obs, _)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent_fn\u001b[39m(obs: t\u001b[38;5;241m.\u001b[39mAny, _: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[13], line 364\u001b[0m, in \u001b[0;36mobserve\u001b[0;34m(obs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguess\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 364\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[43mguess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n","Cell \u001b[0;32mIn[13], line 237\u001b[0m, in \u001b[0;36mguess\u001b[0;34m(observation)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG____ASSESS FOR HISTORY PROMPT (GUESSER): \u001b[39m\u001b[38;5;124m\"\u001b[39m, hx_text)\n\u001b[0;32m--> 237\u001b[0m hx_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhx_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m thinking_text \u001b[38;5;241m=\u001b[39m thinking_for_guess(hx_text)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n","Cell \u001b[0;32mIn[13], line 305\u001b[0m, in \u001b[0;36mgenerate_text_long\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    303\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    304\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer([text], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 305\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m [output_ids[\u001b[38;5;28mlen\u001b[39m(input_ids):] \u001b[38;5;28;01mfor\u001b[39;00m input_ids, output_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs\u001b[38;5;241m.\u001b[39minput_ids, generated_ids)]\n\u001b[1;32m    307\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi3/modeling_phi3.py:1253\u001b[0m, in \u001b[0;36mPhi3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1250\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1253\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1266\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi3/modeling_phi3.py:1131\u001b[0m, in \u001b[0;36mPhi3Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1122\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         use_cache,\n\u001b[1;32m   1129\u001b[0m     )\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi3/modeling_phi3.py:870\u001b[0m, in \u001b[0;36mPhi3DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    866\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_mlp_dropout(hidden_states)\n\u001b[1;32m    868\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    871\u001b[0m     outputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (self_attn_weights,)\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}