{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61247,"databundleVersionId":8550470,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/matthewsfarmer/solution-l3-1-8b-inst-kraut?scriptVersionId=193016878\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import subprocess\n\ndef execute_command(cmd):\n    result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    if result.returncode == 0:\n        print(f'Work Complete! {cmd} ')\n    else:\n        print(f'We are being attacked!! {cmd}')\n        print(result.stdout.decode('utf-8'))\n\nexecute_command(\"huggingface-cli download VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct --local-dir /tmp/submission/\")\nexecute_command(\"pip install -t /tmp/submission/lib bitsandbytes outlines\")\nexecute_command(\"pip install bitsandbytes outlines\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-17T22:32:43.572793Z","iopub.execute_input":"2024-08-17T22:32:43.573061Z","iopub.status.idle":"2024-08-17T22:38:05.771731Z","shell.execute_reply.started":"2024-08-17T22:32:43.573037Z","shell.execute_reply":"2024-08-17T22:38:05.770646Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Work Complete! huggingface-cli download VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct --local-dir /tmp/submission/ \nWork Complete! pip install -t /tmp/submission/lib bitsandbytes outlines \nWork Complete! pip install bitsandbytes outlines \n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nwith open(\"/tmp/submission/config.json\", \"r\") as file:\n    config = json.load(file)\nconfig[\"rope_scaling\"] = {\"factor\": 4.0,\"type\":\"dynamic\"}\nwith open(\"/tmp/submission/config.json\", \"w\") as file:\n    json.dump(config, file)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T22:39:34.86116Z","iopub.execute_input":"2024-08-17T22:39:34.861524Z","iopub.status.idle":"2024-08-17T22:39:34.868339Z","shell.execute_reply.started":"2024-08-17T22:39:34.861501Z","shell.execute_reply":"2024-08-17T22:39:34.867566Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#%%writefile main.py\n\n# ====================ENV PATH========================\n\nimport os\nimport sys\n\nKAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\nif not os.path.exists(KAGGLE_AGENT_PATH):\n    KAGGLE_AGENT_PATH = \"/tmp/submission/\"\n\nif os.path.exists(KAGGLE_AGENT_PATH):\n    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\nelse:\n    sys.path.insert(0, \"/tmp/submission/lib\")\n    \n# ====================IMPORTS=========================\n\nimport json\nimport itertools\nimport re\nimport random\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import List\nimport typing as t\n\nimport torch\nfrom pydantic import BaseModel, Field\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nimport outlines\nfrom outlines import generate, samplers\n\n# ====================CONSTANTS========================\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True, \n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\nmodel_kwargs = {\n    \"quantization_config\": quantization_config, \n    \"trust_remote_code\": True,\n}\n\nsystem_token = '<|begin_of_text|><|start_header_id|>system<|end_header_id|>'\nuser_token = '<|start_header_id|>user<|end_header_id|>'\nassistant_token = '<|start_header_id|>assistant<|end_header_id|>'\neot = '<|eot_id|>'\n\n# ====================INITIALIZATION========================\n\nif 'model' in locals() and model is not None:\n    print(\"Model already loaded. Skipping creation.\")\nelse:    \n    model = outlines.models.transformers(KAGGLE_AGENT_PATH,device=device, model_kwargs=model_kwargs)\n    \n# =====================CLASSES=========================\n\nclass Observation(BaseModel):\n    step: int\n    role: t.Literal[\"guesser\", \"answerer\"]\n    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]\n    keyword: str\n    category: str\n    questions: list[str]\n    answers: list[str]\n    guesses: list[str]\n\n    @property\n    def empty(self) -> bool:\n        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])\n\n    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")\n\n    def qa_history_as_numbered_list(self) -> str:\n        if not self.empty:\n            history = \"\\n\".join(\n                f\"{i + 1}. {question} : {answer}\"\n                for i, (question, answer, guess) in enumerate(self.get_history())\n            )\n            return history\n        return \"none yet.\"\n    \n    def get_list_of_guesses(self) -> str:\n        return ', '.join(self.guesses)\n    \n    def get_qa_as_dict(self) -> dict:\n        return {\n            \"step\": self.step,\n            \"questions\": self.questions,\n            \"answers\": self.answers\n        }\n    \n\n    \nclass YesNoEnum(str, Enum):\n    yes = \"yes\"\n    no = \"no\"\n    \nclass Answer(BaseModel):\n    internal_thoughts: str = Field(\n        description=\"A short statement explaining the reasoning for your answer to the question.\",\n        example= \"My keyword is cinnamon roll, since the question asked is it a living thing? my answer is no. A cinnamon roll is not a living thing\",\n    )\n    answer: YesNoEnum\n\nclass Question(BaseModel):\n    internal_thoughts: str = Field(\n        description=\"A short statement deductively summarizing the game history and coming to a conclusion on the next question to ask\",\n        example=\"We know that the keyword is a living thing and a pet, so the question 'is it a mammal?' further narrows the possibilities.\",\n    )\n    question: str = Field(\n        description=\"A simple yes/no question. Ending in a question mark.\", \n        example=\"Is it a living thing?\", \n        max_length= 150\n    )\n    probable_secret_keyword: str = Field(\n        description=\"The most probable keyword, based on the game history\", \n        example=\"purse\",  \n    )\n\nclass Guess(BaseModel):\n    internal_thoughts: str = Field(\n        description=\"A short statement reviewing the game history and coming to a conclusion on most probably keyword\", \n        example=\"We know that the keyword is a living thing and a pet, so dog would be a likely keyword\", \n    )\n    guess: str = Field(\n        description=\" This is the most probable keyword based on the current game history and does not repeat previous keywords\", \n        example = \"jellybean\", \n        max_length=50\n    )\n \n    \n    \n# =====================QUESTIONER AGENT=========================\n\ndef ask(observation):\n    try:\n        qa_hx = observation.qa_history_as_numbered_list()\n        prompt = questioner(qa_hx)\n        sampler = samplers.multinomial(1, temperature=0.45, top_p=0.95)\n        q_generator = generate.json(model, Question, sampler=sampler)\n        output = q_generator(prompt, max_tokens=550)\n        q_dict = output.dict()\n        question = q_dict[\"question\"]\n        return question \n    except Exception as e:\n        print(e)\n        return \"Is the keyword just a single word?\"\n\ndef questioner(qa_hx, system_token=system_token, user_token=user_token, assistant_token=assistant_token, eot=eot):\n    return f\"\"\"\n{system_token}\nYou are the questioner in a game of 20 Questions. Your goal is to ask questions that help discover the identity of the secret keyword by asking yes/no questions.\nThe user is thinking of a keyword. The keyword will not be a person or geography (city, country, mountain, river, etc.)\n\nAs questioner, here the optimal strategy you should follow:\n\n- Start Broad: Begin with questions that can divide the category into large, distinct groups. This helps to halve the possible options quickly.\n- Use Binary Splitting: Ask questions that roughly split the remaining possibilities in half to narrow down the options more efficiently.\n- Narrow Down Attributes: Once you have a smaller subset, focus on specific attributes to further narrow down the options.\n- Keep Track: You will receive a question and answer history to track the game progress.\n- Balance Specificity and Breadth: Avoid questions that are too narrow too early, as they might not be as effective in eliminating large groups of possibilities.\n- Adapt Based on Answers: Be flexible and ready to change your line of questioning based on the answers you receive. If you are getting many no's, consider changing your approach and backtracking to a previous question/reasoning that led to a yes.\n- Avoid Redundancy: Make sure each question adds new information and doesn't rehash what you already know.\n{eot}\n{user_token}\nGame History:\n\n{qa_hx}\n\n{eot}\n{assistant_token}\n\"\"\"\n\n\n# =====================ANSWERER AGENT=========================\n\ndef answer(observation):\n    try:\n        last_question = observation.questions[-1]\n        keyword = observation.keyword\n        category = observation.category\n        prompt = answerer(last_question, keyword, category)\n        sampler = samplers.multinomial(1, temperature=0.25, top_p=0.95)\n        a_generator = generate.json(model, Answer, sampler=sampler)\n        output = a_generator(prompt, max_tokens=200)\n        a_dict = output.dict()\n        answer = a_dict[\"answer\"]\n        answer = answer.value\n        return answer\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return \"no\"\n\n\ndef answerer(question, keyword, category, system_token=system_token, user_token=user_token, assistant_token=assistant_token, eot=eot):\n    return f\"\"\"\n{system_token}\nYou are an AI designed to truthfully answer yes/no questions about a secret keyword in the game 20 questions.\nYou are the answerer. You answer the user's questions about the secret keyword. \nIf the question is nonsensical or not a valid question, you respond with no.\n{eot}\n{user_token}\nHere is the question to be answered:\n\n\"{question}\"\n\nThis is your keyword: {keyword}\n\nThink about the question in context with the keyword and category to form your yes or no answer.\nAnswer using the most common understanding of the keyword, do not use an obscure context or far-fetched assumption of the keyword that may not be well-known.\nIs the answer yes or no? Provide your reasoning for your answer. \n{eot}\n{assistant_token}\n\"\"\"\n\n# =====================GUESSER AGENT=========================\ndef guess(observation):\n    if len(observation.guesses) == 0:\n        guess_hx = \"no guess yet\"\n    else: \n        guess_hx = observation.get_list_of_guesses()\n    try:    \n        qa_hx = observation.qa_history_as_numbered_list()\n        prompt = guesser(qa_hx, guess_hx)\n        sampler = samplers.multinomial(1, temperature=0.4, top_p=0.95)\n        g_generator = outlines.generate.json(model, Guess, sampler=sampler)\n        output = g_generator(prompt, max_tokens=550)\n        g_dict = output.dict()\n        guess = g_dict[\"guess\"]\n        return guess.lower().replace(\"_\", \" \").strip()\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return \"I think I need more information...\"\n\ndef guesser(qa_hx, guess_hx, system_token=system_token, user_token=user_token, assistant_token=assistant_token, eot=eot):   \n    return f\"\"\"\n{system_token}\nYou are an intelligent agent tasked with guessing the keyword in a game of 20 Questions. \nThe keyword belongs to one of the following categories but can overlap into multiple categories: \nhome items, furniture, lifestyle, hygiene/beauty, technology/electronics, safety/secrurity, health/medical, tools/equipment, professional/office items, transportation/vehicles, food/drink, outdoors, living things (pets, animals, plants, etc.), non-living things found in nature, or toys/games/sports. \n\nThe keyword will not be a person or a geographical location (such as cities, countries, or natural landmarks) and will never be longer than 3 words.\n\nGuidelines:\n    - Use the provided question and answer history to narrow down the possibilities.\n    - Apply logical deduction to eliminate options that do not fit the answers.\n    - Consider the categories and attributes that have been confirmed or ruled out by the questions.\n    - Your output should be a single guess of the keyword, based on the history provided.\n{eot}\n{user_token}\nHere is the game history:\n\n{qa_hx}\n\nPreviously incorrect guesses: \n\n{guess_hx}\n\nStrategies:\n- The keyword is likely to be a common thing that would be known by most people.\n- In early game, you will probably be making a wild guess. That's okay. \n- As the game progresses, and you become more confident in your guess, try variations of similar things to form new guesses.\n- Don't repeat your guesses, since we know that they were incorrect.\n- Just because the keyword was incorrect does not mean that the category the keyword belongs to is ruled out.\n    - For example if the secret keyword is oak tree and the guess was tree, the keyword was not guessed correctly but it is on the right track!\n- Guesses should deploy a wide variety of categories and vocabularies from common, less common, and even obscure words or multi-word things. \n    - For example a secret keyword could be: \"cookie\"(common food) or \"mattress\"(less common home item/furniture), or \"turnstiles\"(obscure man-made object), or \"hot dog\" (multi-word food)\n\nWhat is our next guess that hasn't been used before and your reasoning process?\n{eot}\n{assistant_token}\n\"\"\"\n    \n# ======================GAME FUNCTIONS========================\nagent = None\n\ndef observe(obs: t.Any) -> str:\n    global agent\n    observation = Observation(**obs.__dict__)\n\n    try:\n        match observation.turnType:\n            case \"ask\":\n                agent = ask(observation)\n                return agent\n            case \"answer\":\n                agent = answer(observation)\n                return agent\n            case \"guess\":\n                agent = guess(observation)\n                return agent\n\n            case _:\n                raise ValueError(\"Unknown turn type\")\n    except Exception as e:\n        print(str(e), file=sys.stderr)\n        raise\n\ndef agent_fn(obs: t.Any, _: t.Any) -> str:\n    return observe(obs)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T22:41:59.13597Z","iopub.execute_input":"2024-08-17T22:41:59.136363Z","iopub.status.idle":"2024-08-17T22:41:59.184624Z","shell.execute_reply.started":"2024-08-17T22:41:59.136333Z","shell.execute_reply":"2024-08-17T22:41:59.183714Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model already loaded. Skipping creation.\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nimport json\nimport re\nimport typing as t\nimport random\nimport time\n\n# List of keywords to be used for testing\nkeywords_list = [\n    'alligator clip', 'armadillo', 'barracks', 'beech', 'boardwalk', 'bobcat', 'bubble', 'bucket', 'bunker', 'camera',\n    'ceiling fan', 'celery', 'court file', 'cow', 'cruiser bike', 'cupping', 'door handle', 'emergency siren', 'eyelash',\n    'fabric glue', 'fawn', 'garage', 'garlic', 'glacier', 'golf', 'guinea pig', 'hairpin', 'jug', 'kart', 'lilypad',\n    'lobster', 'meringue', 'neon', 'orchid', 'peach', 'plate', 'plier', 'poster', 'pufferfish', 'railway', 'rat', 'sea',\n    'spanish moss', 'stair', 'steel', 'styrofoam', 'terrace', 'trout', 'underwire', 'wallet'\n]\n\nclass MockObservation:\n    def __init__(self, step: int, role: str, turnType: str, keyword: str, category: str, questions: list[str], answers: list[str], guesses: list[str]):\n        self.step = step\n        self.role = role\n        self.turnType = turnType\n        self.keyword = keyword\n        self.category = category\n        self.questions = questions\n        self.answers = answers\n        self.guesses = guesses\n\ndef play_game(keyword):\n    step = 0\n    role = \"answerer\"\n    turnType = \"ask\"\n    category = \"thing\"\n    questions = []\n    answers = []\n    guesses = []\n    print(\"Starting 20 questions eval game...\")\n    print(\"Keyword:\", keyword)\n\n    for i in range(60):\n        obs = MockObservation(step, role, turnType, keyword, category, questions, answers, guesses)\n\n        start_time = time.time()\n        response = agent_fn(obs, None)\n        end_time = time.time()\n\n        response_time = end_time - start_time\n\n        # Record the response in the appropriate list\n        if turnType == 'ask':\n            questions.append(response)\n            turnType = 'answer'\n        elif turnType == 'answer':\n            answers.append(response)\n            turnType = 'guess'\n        elif turnType == 'guess':\n            guesses.append(response)\n            if response.lower() == keyword.lower():\n                print(f\"Keyword '{keyword}' guessed correctly! Ending game.\")\n                return True\n            turnType = 'ask'\n            step += 1\n            role = 'guesser' if role == 'answerer' else 'answerer'\n\n        print(f\"Round {step}: {response} {response_time:.2f} sec\")\n    return False\n\n# Run the test for each keyword and calculate the win rate\ncorrect_guesses = 0\ntotal_games = len(keywords_list)\n\nfor keyword in keywords_list:\n    if play_game(keyword):\n        correct_guesses += 1\n\nwin_rate = (correct_guesses / total_games) * 100\nprint(f\"Win Rate: {win_rate:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T22:42:01.895362Z","iopub.execute_input":"2024-08-17T22:42:01.895708Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Starting 20 questions eval game...\nKeyword: alligator clip\n","output_type":"stream"},{"name":"stderr","text":"Compiling FSM index for all state transitions: 100%|██████████| 990/990 [01:26<00:00, 11.45it/s]\nWe detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n2024-08-17 22:44:00.818202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-17 22:44:00.818308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-17 22:44:01.099650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Round 0: Is the keyword something man-made? 139.53 sec\n","output_type":"stream"}]}]}